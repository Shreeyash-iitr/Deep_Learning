{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats_V_S_Dogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Shreeyash-iitr/Deep_Learning/blob/master/Cats_V_S_Dogs.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "qcHl86MSYBET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ib_mUR0nYG0J",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "d9d1047f-b30e-4fad-dc3d-01bf26ad9f4f"
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-393f709e-60ae-434a-b88b-21980cdbcdb7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-393f709e-60ae-434a-b88b-21980cdbcdb7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"shreeyash6199\",\"key\":\"fa0ace82f613ab882fd3fb0b94916db0\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "LrDe5by2YKv-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ttj_yNmAYTW-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AEeewa2GYcvt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "chvxHf-O9iBp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">Now download kaggle dataset."
      ]
    },
    {
      "metadata": {
        "id": "GFSBLQhDYzY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "89cedd30-cab8-445d-949c-ffa307aba57f"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by otherusers on this system! To fix this, you can run'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading test.zip to /content\n",
            " 94%|██████████████████████████████████████▍  | 254M/271M [00:02<00:00, 118MB/s]\n",
            "100%|█████████████████████████████████████████| 271M/271M [00:02<00:00, 132MB/s]\n",
            "Downloading train.zip to /content\n",
            " 99%|████████████████████████████████████████▋| 539M/544M [00:04<00:00, 189MB/s]\n",
            "100%|█████████████████████████████████████████| 544M/544M [00:04<00:00, 140MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0%|                                                | 0.00/111k [00:00<?, ?B/s]\n",
            "100%|████████████████████████████████████████| 111k/111k [00:00<00:00, 53.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1BonJuTAZI_r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAo4VHK5a9Jm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip test.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HUNg_EMCbBnx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6bp8Ve3-Wiw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   import all required libraries \n",
        "*   we will use tensorflow layers framework.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "U_FSMaPgauJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4fJ-I3lAA35",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Preprocessing Images**\n",
        "\n",
        "> >resizing images to shape (100,100,3) and then storing dataset into a numpy array. OpenCV is used for basic processing on images.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kP0Byl27c2d8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for img in os.listdir('train/'):\n",
        "    path = \"train/\" + str(img) \n",
        "    image = cv2.imread(str(path))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image,(64,64))\n",
        "    images.append(image)\n",
        "    if img[:3] == \"cat\":                  # cat >> 0\n",
        "        labels.append(int(0))\n",
        "    elif img[:3] == \"dog\":                # dog >> 1\n",
        "        labels.append(int(1))\n",
        "\n",
        "images = numpy.array(images)\n",
        "labels = numpy.array(labels)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o99TJLMGAczt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> > Note that here I am reshaping y_train and y_test array to [-1,1] because it will convert its shape from (?, ) to (?, 1). It will reduce future errors. "
      ]
    },
    {
      "metadata": {
        "id": "A13344MyeF4V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn.cross_validation\n",
        "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(images, labels, test_size=0.05)\n",
        "y_train = numpy.asarray(y_train, dtype = 'int')\n",
        "y_train = numpy.reshape(y_train,[-1,1])\n",
        "y_test = numpy.reshape(y_test,[-1,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSdy3-y1egq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "4d37d565-41b4-4d42-d950-a60c17330344"
      },
      "cell_type": "code",
      "source": [
        "gray = cv2.cvtColor(X_test[1], cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(gray)\n",
        "y_test[1]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTYBY6IFAEyAWeiDQBPj/d7euUArO0MQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f420a2a7160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HkuATUHXaJU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kgPmm4ZDD0sq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=3,activation=layers.activations.relu,data_format='channels_last',input_shape=[64,64,3]))\n",
        "model.add(layers.MaxPool2D(pool_size=2,strides=2))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=3,activation=layers.activations.relu))\n",
        "model.add(layers.MaxPool2D(pool_size=2,strides=2))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=3,activation=layers.activations.relu))\n",
        "model.add(layers.MaxPool2D(pool_size=2,strides=2))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=3,activation=layers.activations.relu))\n",
        "model.add(layers.MaxPool2D(pool_size=2,strides=2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128,activation=layers.activations.relu))\n",
        "model.add(layers.Dense(128,activation=layers.activations.relu))\n",
        "model.add(layers.Dense(2, activation=layers.activations.softmax))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MCKfrWBKJNLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = keras.optimizers.Adam(lr=1e-5),loss = keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjZI0al1KVC4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "tensorboard_ = TensorBoard(log_dir=\"logs/{}\".format(time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RW0SHkHUHeXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3788
        },
        "outputId": "e7d3eb22-6ac6-455e-ff4a-ccea3e4fac5e"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train, y=y_train, batch_size=128, epochs=100,verbose=2,validation_split = 0.1, callbacks=[tensorboard_])\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 21375 samples, validate on 2375 samples\n",
            "Epoch 1/100\n",
            " - 9s - loss: 0.3762 - acc: 0.8351 - val_loss: 0.4274 - val_acc: 0.8034\n",
            "Epoch 2/100\n",
            " - 9s - loss: 0.3733 - acc: 0.8383 - val_loss: 0.4247 - val_acc: 0.8025\n",
            "Epoch 3/100\n",
            " - 9s - loss: 0.3726 - acc: 0.8366 - val_loss: 0.4302 - val_acc: 0.8008\n",
            "Epoch 4/100\n",
            " - 9s - loss: 0.3685 - acc: 0.8406 - val_loss: 0.4217 - val_acc: 0.8029\n",
            "Epoch 5/100\n",
            " - 9s - loss: 0.3680 - acc: 0.8400 - val_loss: 0.4249 - val_acc: 0.8059\n",
            "Epoch 6/100\n",
            " - 9s - loss: 0.3687 - acc: 0.8372 - val_loss: 0.4207 - val_acc: 0.8059\n",
            "Epoch 7/100\n",
            " - 9s - loss: 0.3693 - acc: 0.8363 - val_loss: 0.4262 - val_acc: 0.7987\n",
            "Epoch 8/100\n",
            " - 9s - loss: 0.3646 - acc: 0.8401 - val_loss: 0.4195 - val_acc: 0.8067\n",
            "Epoch 9/100\n",
            " - 9s - loss: 0.3597 - acc: 0.8451 - val_loss: 0.4222 - val_acc: 0.8042\n",
            "Epoch 10/100\n",
            " - 9s - loss: 0.3580 - acc: 0.8464 - val_loss: 0.4206 - val_acc: 0.8063\n",
            "Epoch 11/100\n",
            " - 9s - loss: 0.3534 - acc: 0.8494 - val_loss: 0.4221 - val_acc: 0.7996\n",
            "Epoch 12/100\n",
            " - 9s - loss: 0.3530 - acc: 0.8485 - val_loss: 0.4269 - val_acc: 0.8013\n",
            "Epoch 13/100\n",
            " - 9s - loss: 0.3494 - acc: 0.8487 - val_loss: 0.4156 - val_acc: 0.8093\n",
            "Epoch 14/100\n",
            " - 9s - loss: 0.3482 - acc: 0.8510 - val_loss: 0.4185 - val_acc: 0.8021\n",
            "Epoch 15/100\n",
            " - 9s - loss: 0.3465 - acc: 0.8501 - val_loss: 0.4150 - val_acc: 0.8105\n",
            "Epoch 16/100\n",
            " - 9s - loss: 0.3451 - acc: 0.8517 - val_loss: 0.4167 - val_acc: 0.8034\n",
            "Epoch 17/100\n",
            " - 9s - loss: 0.3436 - acc: 0.8516 - val_loss: 0.4144 - val_acc: 0.8059\n",
            "Epoch 18/100\n",
            " - 9s - loss: 0.3397 - acc: 0.8558 - val_loss: 0.4236 - val_acc: 0.8114\n",
            "Epoch 19/100\n",
            " - 9s - loss: 0.3357 - acc: 0.8586 - val_loss: 0.4120 - val_acc: 0.8114\n",
            "Epoch 20/100\n",
            " - 9s - loss: 0.3383 - acc: 0.8563 - val_loss: 0.4436 - val_acc: 0.8021\n",
            "Epoch 21/100\n",
            " - 9s - loss: 0.3327 - acc: 0.8582 - val_loss: 0.4168 - val_acc: 0.8021\n",
            "Epoch 22/100\n",
            " - 9s - loss: 0.3351 - acc: 0.8571 - val_loss: 0.4130 - val_acc: 0.8067\n",
            "Epoch 23/100\n",
            " - 9s - loss: 0.3265 - acc: 0.8618 - val_loss: 0.4122 - val_acc: 0.8101\n",
            "Epoch 24/100\n",
            " - 9s - loss: 0.3320 - acc: 0.8565 - val_loss: 0.4139 - val_acc: 0.8088\n",
            "Epoch 25/100\n",
            " - 9s - loss: 0.3232 - acc: 0.8655 - val_loss: 0.4338 - val_acc: 0.7983\n",
            "Epoch 26/100\n",
            " - 9s - loss: 0.3297 - acc: 0.8590 - val_loss: 0.4179 - val_acc: 0.8013\n",
            "Epoch 27/100\n",
            " - 9s - loss: 0.3211 - acc: 0.8648 - val_loss: 0.4207 - val_acc: 0.8013\n",
            "Epoch 28/100\n",
            " - 9s - loss: 0.3220 - acc: 0.8628 - val_loss: 0.4173 - val_acc: 0.8034\n",
            "Epoch 29/100\n",
            " - 9s - loss: 0.3161 - acc: 0.8698 - val_loss: 0.4127 - val_acc: 0.8105\n",
            "Epoch 30/100\n",
            " - 9s - loss: 0.3168 - acc: 0.8665 - val_loss: 0.4162 - val_acc: 0.8055\n",
            "Epoch 31/100\n",
            " - 9s - loss: 0.3133 - acc: 0.8694 - val_loss: 0.4081 - val_acc: 0.8097\n",
            "Epoch 32/100\n",
            " - 9s - loss: 0.3116 - acc: 0.8698 - val_loss: 0.4079 - val_acc: 0.8131\n",
            "Epoch 33/100\n",
            " - 9s - loss: 0.3122 - acc: 0.8695 - val_loss: 0.4064 - val_acc: 0.8131\n",
            "Epoch 34/100\n",
            " - 9s - loss: 0.3072 - acc: 0.8715 - val_loss: 0.4198 - val_acc: 0.8084\n",
            "Epoch 35/100\n",
            " - 9s - loss: 0.3066 - acc: 0.8735 - val_loss: 0.4048 - val_acc: 0.8173\n",
            "Epoch 36/100\n",
            " - 9s - loss: 0.3039 - acc: 0.8721 - val_loss: 0.4271 - val_acc: 0.8084\n",
            "Epoch 37/100\n",
            " - 9s - loss: 0.3010 - acc: 0.8770 - val_loss: 0.4487 - val_acc: 0.8042\n",
            "Epoch 38/100\n",
            " - 9s - loss: 0.3018 - acc: 0.8735 - val_loss: 0.4060 - val_acc: 0.8156\n",
            "Epoch 39/100\n",
            " - 9s - loss: 0.3007 - acc: 0.8756 - val_loss: 0.4063 - val_acc: 0.8177\n",
            "Epoch 40/100\n",
            " - 9s - loss: 0.2992 - acc: 0.8756 - val_loss: 0.4105 - val_acc: 0.8109\n",
            "Epoch 41/100\n",
            " - 9s - loss: 0.2940 - acc: 0.8779 - val_loss: 0.4045 - val_acc: 0.8185\n",
            "Epoch 42/100\n",
            " - 9s - loss: 0.2926 - acc: 0.8811 - val_loss: 0.4187 - val_acc: 0.8088\n",
            "Epoch 43/100\n",
            " - 9s - loss: 0.2890 - acc: 0.8814 - val_loss: 0.4042 - val_acc: 0.8181\n",
            "Epoch 44/100\n",
            " - 9s - loss: 0.2859 - acc: 0.8839 - val_loss: 0.4060 - val_acc: 0.8177\n",
            "Epoch 45/100\n",
            " - 9s - loss: 0.2837 - acc: 0.8834 - val_loss: 0.4044 - val_acc: 0.8181\n",
            "Epoch 46/100\n",
            " - 9s - loss: 0.2849 - acc: 0.8857 - val_loss: 0.4054 - val_acc: 0.8177\n",
            "Epoch 47/100\n",
            " - 9s - loss: 0.2822 - acc: 0.8846 - val_loss: 0.4048 - val_acc: 0.8185\n",
            "Epoch 48/100\n",
            " - 9s - loss: 0.2808 - acc: 0.8862 - val_loss: 0.4038 - val_acc: 0.8194\n",
            "Epoch 49/100\n",
            " - 9s - loss: 0.2768 - acc: 0.8893 - val_loss: 0.4222 - val_acc: 0.8042\n",
            "Epoch 50/100\n",
            " - 8s - loss: 0.2778 - acc: 0.8863 - val_loss: 0.4140 - val_acc: 0.8143\n",
            "Epoch 51/100\n",
            " - 9s - loss: 0.2714 - acc: 0.8911 - val_loss: 0.4042 - val_acc: 0.8215\n",
            "Epoch 52/100\n",
            " - 9s - loss: 0.2720 - acc: 0.8910 - val_loss: 0.4285 - val_acc: 0.8093\n",
            "Epoch 53/100\n",
            " - 9s - loss: 0.2692 - acc: 0.8893 - val_loss: 0.4157 - val_acc: 0.8126\n",
            "Epoch 54/100\n",
            " - 9s - loss: 0.2725 - acc: 0.8906 - val_loss: 0.4057 - val_acc: 0.8181\n",
            "Epoch 55/100\n",
            " - 9s - loss: 0.2658 - acc: 0.8914 - val_loss: 0.4037 - val_acc: 0.8261\n",
            "Epoch 56/100\n",
            " - 9s - loss: 0.2651 - acc: 0.8947 - val_loss: 0.4130 - val_acc: 0.8152\n",
            "Epoch 57/100\n",
            " - 9s - loss: 0.2642 - acc: 0.8949 - val_loss: 0.4043 - val_acc: 0.8236\n",
            "Epoch 58/100\n",
            " - 9s - loss: 0.2584 - acc: 0.8978 - val_loss: 0.4052 - val_acc: 0.8211\n",
            "Epoch 59/100\n",
            " - 9s - loss: 0.2585 - acc: 0.8971 - val_loss: 0.4160 - val_acc: 0.8109\n",
            "Epoch 60/100\n",
            " - 9s - loss: 0.2563 - acc: 0.8982 - val_loss: 0.4099 - val_acc: 0.8211\n",
            "Epoch 61/100\n",
            " - 9s - loss: 0.2568 - acc: 0.8980 - val_loss: 0.4042 - val_acc: 0.8240\n",
            "Epoch 62/100\n",
            " - 9s - loss: 0.2511 - acc: 0.9030 - val_loss: 0.4094 - val_acc: 0.8189\n",
            "Epoch 63/100\n",
            " - 9s - loss: 0.2511 - acc: 0.8994 - val_loss: 0.4078 - val_acc: 0.8261\n",
            "Epoch 64/100\n",
            " - 9s - loss: 0.2489 - acc: 0.9010 - val_loss: 0.4254 - val_acc: 0.8080\n",
            "Epoch 65/100\n",
            " - 9s - loss: 0.2472 - acc: 0.9039 - val_loss: 0.4082 - val_acc: 0.8248\n",
            "Epoch 66/100\n",
            " - 9s - loss: 0.2430 - acc: 0.9053 - val_loss: 0.4198 - val_acc: 0.8122\n",
            "Epoch 67/100\n",
            " - 9s - loss: 0.2449 - acc: 0.9039 - val_loss: 0.4075 - val_acc: 0.8198\n",
            "Epoch 68/100\n",
            " - 9s - loss: 0.2416 - acc: 0.9044 - val_loss: 0.4232 - val_acc: 0.8097\n",
            "Epoch 69/100\n",
            " - 9s - loss: 0.2415 - acc: 0.9068 - val_loss: 0.4080 - val_acc: 0.8232\n",
            "Epoch 70/100\n",
            " - 9s - loss: 0.2408 - acc: 0.9052 - val_loss: 0.4446 - val_acc: 0.8013\n",
            "Epoch 71/100\n",
            " - 9s - loss: 0.2364 - acc: 0.9069 - val_loss: 0.4143 - val_acc: 0.8160\n",
            "Epoch 72/100\n",
            " - 9s - loss: 0.2325 - acc: 0.9099 - val_loss: 0.4075 - val_acc: 0.8248\n",
            "Epoch 73/100\n",
            " - 9s - loss: 0.2318 - acc: 0.9093 - val_loss: 0.4111 - val_acc: 0.8240\n",
            "Epoch 74/100\n",
            " - 9s - loss: 0.2296 - acc: 0.9119 - val_loss: 0.4538 - val_acc: 0.8072\n",
            "Epoch 75/100\n",
            " - 9s - loss: 0.2304 - acc: 0.9109 - val_loss: 0.4074 - val_acc: 0.8223\n",
            "Epoch 76/100\n",
            " - 9s - loss: 0.2283 - acc: 0.9104 - val_loss: 0.4132 - val_acc: 0.8232\n",
            "Epoch 77/100\n",
            " - 9s - loss: 0.2236 - acc: 0.9156 - val_loss: 0.4102 - val_acc: 0.8227\n",
            "Epoch 78/100\n",
            " - 9s - loss: 0.2208 - acc: 0.9152 - val_loss: 0.4097 - val_acc: 0.8215\n",
            "Epoch 79/100\n",
            " - 9s - loss: 0.2186 - acc: 0.9177 - val_loss: 0.4105 - val_acc: 0.8253\n",
            "Epoch 80/100\n",
            " - 9s - loss: 0.2143 - acc: 0.9201 - val_loss: 0.4212 - val_acc: 0.8211\n",
            "Epoch 81/100\n",
            " - 9s - loss: 0.2235 - acc: 0.9125 - val_loss: 0.4216 - val_acc: 0.8232\n",
            "Epoch 82/100\n",
            " - 9s - loss: 0.2153 - acc: 0.9201 - val_loss: 0.4150 - val_acc: 0.8274\n",
            "Epoch 83/100\n",
            " - 9s - loss: 0.2135 - acc: 0.9187 - val_loss: 0.4243 - val_acc: 0.8177\n",
            "Epoch 84/100\n",
            " - 9s - loss: 0.2126 - acc: 0.9178 - val_loss: 0.4125 - val_acc: 0.8227\n",
            "Epoch 85/100\n",
            " - 9s - loss: 0.2081 - acc: 0.9207 - val_loss: 0.4175 - val_acc: 0.8232\n",
            "Epoch 86/100\n",
            " - 9s - loss: 0.2055 - acc: 0.9247 - val_loss: 0.4141 - val_acc: 0.8236\n",
            "Epoch 87/100\n",
            " - 9s - loss: 0.2071 - acc: 0.9216 - val_loss: 0.4232 - val_acc: 0.8232\n",
            "Epoch 88/100\n",
            " - 9s - loss: 0.2038 - acc: 0.9245 - val_loss: 0.4467 - val_acc: 0.8168\n",
            "Epoch 89/100\n",
            " - 9s - loss: 0.1996 - acc: 0.9267 - val_loss: 0.4161 - val_acc: 0.8223\n",
            "Epoch 90/100\n",
            " - 9s - loss: 0.1984 - acc: 0.9272 - val_loss: 0.4166 - val_acc: 0.8211\n",
            "Epoch 91/100\n",
            " - 9s - loss: 0.1981 - acc: 0.9263 - val_loss: 0.4213 - val_acc: 0.8265\n",
            "Epoch 92/100\n",
            " - 9s - loss: 0.1979 - acc: 0.9258 - val_loss: 0.4268 - val_acc: 0.8244\n",
            "Epoch 93/100\n",
            " - 9s - loss: 0.1948 - acc: 0.9279 - val_loss: 0.4209 - val_acc: 0.8236\n",
            "Epoch 94/100\n",
            " - 9s - loss: 0.1913 - acc: 0.9309 - val_loss: 0.4230 - val_acc: 0.8219\n",
            "Epoch 95/100\n",
            " - 9s - loss: 0.1918 - acc: 0.9294 - val_loss: 0.4439 - val_acc: 0.8206\n",
            "Epoch 96/100\n",
            " - 9s - loss: 0.1884 - acc: 0.9326 - val_loss: 0.4187 - val_acc: 0.8219\n",
            "Epoch 97/100\n",
            " - 9s - loss: 0.1860 - acc: 0.9321 - val_loss: 0.4200 - val_acc: 0.8185\n",
            "Epoch 98/100\n",
            " - 9s - loss: 0.1923 - acc: 0.9273 - val_loss: 0.4539 - val_acc: 0.8181\n",
            "Epoch 99/100\n",
            " - 9s - loss: 0.1804 - acc: 0.9376 - val_loss: 0.4266 - val_acc: 0.8219\n",
            "Epoch 100/100\n",
            " - 9s - loss: 0.1856 - acc: 0.9322 - val_loss: 0.4373 - val_acc: 0.8257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4158e74cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSpb3k3dPte_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c6d0b778-a3bd-4611-9e6f-2b200ab8af74"
      },
      "cell_type": "code",
      "source": [
        "score=model.evaluate(x=X_test, y=y_test)\n",
        "print(score)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 0s 291us/step\n",
            "[0.4247236147105694, 0.8184]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L-0hy_N2Oi0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "32a76f2b-74f1-4509-b3dd-7460a3e0544c"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 512)         590336    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 962,626\n",
            "Trainable params: 962,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6BOvqSO5Lzhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1966
        },
        "outputId": "c52f9b25-02f7-46f5-efd5-468cdbe46f02"
      },
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(layers.Conv2D(filters=32, kernel_size=3,activation=layers.activations.relu,data_format='channels_last',input_shape=[64,64,3]))\n",
        "model2.add(layers.MaxPool2D(pool_size=2,strides=2))\n",
        "model2.add(layers.Conv2D(filters=64, kernel_size=3,activation=layers.activations.relu))\n",
        "model2.add(layers.MaxPool2D(pool_size=2,strides=2))\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(128,activation=layers.activations.relu))\n",
        "model2.add(layers.Dense(128,activation=layers.activations.relu))\n",
        "model2.add(layers.Dense(2, activation=layers.activations.softmax))\n",
        "model2.compile(optimizer = keras.optimizers.Adam(lr=1e-5),loss = keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'])\n",
        "model2.fit(x=X_train, y=y_train, batch_size=128, epochs=100,verbose=2,validation_split = 0.1)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 21375 samples, validate on 2375 samples\n",
            "Epoch 1/100\n",
            " - 7s - loss: 0.6812 - acc: 0.5777 - val_loss: 0.6672 - val_acc: 0.6219\n",
            "Epoch 2/100\n",
            " - 7s - loss: 0.6545 - acc: 0.6388 - val_loss: 0.6439 - val_acc: 0.6387\n",
            "Epoch 3/100\n",
            " - 7s - loss: 0.6288 - acc: 0.6681 - val_loss: 0.6165 - val_acc: 0.6716\n",
            "Epoch 4/100\n",
            " - 7s - loss: 0.6080 - acc: 0.6811 - val_loss: 0.6007 - val_acc: 0.6762\n",
            "Epoch 5/100\n",
            " - 7s - loss: 0.5927 - acc: 0.6923 - val_loss: 0.5863 - val_acc: 0.6956\n",
            "Epoch 6/100\n",
            " - 7s - loss: 0.5784 - acc: 0.7055 - val_loss: 0.5765 - val_acc: 0.6956\n",
            "Epoch 7/100\n",
            " - 7s - loss: 0.5665 - acc: 0.7146 - val_loss: 0.5660 - val_acc: 0.7069\n",
            "Epoch 8/100\n",
            " - 7s - loss: 0.5564 - acc: 0.7222 - val_loss: 0.5610 - val_acc: 0.7040\n",
            "Epoch 9/100\n",
            " - 7s - loss: 0.5465 - acc: 0.7288 - val_loss: 0.5522 - val_acc: 0.7221\n",
            "Epoch 10/100\n",
            " - 7s - loss: 0.5380 - acc: 0.7360 - val_loss: 0.5469 - val_acc: 0.7158\n",
            "Epoch 11/100\n",
            " - 7s - loss: 0.5310 - acc: 0.7407 - val_loss: 0.5406 - val_acc: 0.7267\n",
            "Epoch 12/100\n",
            " - 7s - loss: 0.5224 - acc: 0.7470 - val_loss: 0.5348 - val_acc: 0.7297\n",
            "Epoch 13/100\n",
            " - 7s - loss: 0.5156 - acc: 0.7533 - val_loss: 0.5278 - val_acc: 0.7381\n",
            "Epoch 14/100\n",
            " - 7s - loss: 0.5098 - acc: 0.7559 - val_loss: 0.5294 - val_acc: 0.7309\n",
            "Epoch 15/100\n",
            " - 7s - loss: 0.5039 - acc: 0.7580 - val_loss: 0.5191 - val_acc: 0.7402\n",
            "Epoch 16/100\n",
            " - 7s - loss: 0.4994 - acc: 0.7636 - val_loss: 0.5156 - val_acc: 0.7415\n",
            "Epoch 17/100\n",
            " - 7s - loss: 0.4929 - acc: 0.7665 - val_loss: 0.5139 - val_acc: 0.7423\n",
            "Epoch 18/100\n",
            " - 7s - loss: 0.4869 - acc: 0.7736 - val_loss: 0.5128 - val_acc: 0.7423\n",
            "Epoch 19/100\n",
            " - 7s - loss: 0.4824 - acc: 0.7757 - val_loss: 0.5067 - val_acc: 0.7461\n",
            "Epoch 20/100\n",
            " - 7s - loss: 0.4780 - acc: 0.7794 - val_loss: 0.5084 - val_acc: 0.7465\n",
            "Epoch 21/100\n",
            " - 7s - loss: 0.4747 - acc: 0.7797 - val_loss: 0.5034 - val_acc: 0.7537\n",
            "Epoch 22/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-536b31d1caab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \"\"\"\n\u001b[1;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 4119\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   4120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4033\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4034\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   4164\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4165\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4166\u001b[0;31m         \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4168\u001b[0m     \u001b[0;31m# Check if the array contains any nan's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ojfR89u5QIif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2bf2e0b1-f283-48e9-df33-dfeeb77b6ee0"
      },
      "cell_type": "code",
      "source": [
        "score2=model2.evaluate(x=X_test, y=y_test)\n",
        "print(score2)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 0s 292us/step\n",
            "[0.4587086442947388, 0.7944]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c1AzHfxAObyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "24820913-45c3-45aa-80b0-e061afbd10ef"
      },
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,641,922\n",
            "Trainable params: 1,641,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TBRLQXQHQGa0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}